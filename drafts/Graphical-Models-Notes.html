<!DOCTYPE HTML>
<html>
<head>
  <meta charset="utf-8">
  
  <title>Graphical-Models-Notes | SunShining</title>
  <meta name="author" content="Yong Jiang">
  
  <meta name="description" content="A blog of a machine learning learner @ShanghaiTech University">
  
  
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">

  <meta property="og:title" content="Graphical-Models-Notes"/>
  <meta property="og:site_name" content="SunShining"/>

  
    <meta property="og:image" content="undefined"/>
  

  
  
    <link href="/favicon.png" rel="icon">
  
  
  <link rel="stylesheet" href="/css/bootstrap.min.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/font-awesome.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/style.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/highlight.css" media="screen" type="text/css">
  <link rel="stylesheet" href="/css/google-fonts.css" media="screen" type="text/css">
  <!--[if lt IE 9]><script src="//html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->

  <script src="/js/jquery-2.0.3.min.js"></script>

  <!-- analytics -->
  



</head>

 <body>  
  <nav id="main-nav" class="navbar navbar-inverse navbar-fixed-top" role="navigation">
    <div class="container">
      <button type="button" class="navbar-header navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
		<span class="sr-only">Toggle navigation</span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
	  <a class="navbar-brand" href="/">SunShining</a>
      <div class="collapse navbar-collapse nav-menu">
		<ul class="nav navbar-nav">
		  
		  <li>
			<a href="/archives" title="All the articles.">
			  <i class="fa fa-archive"></i>Archives
			</a>
		  </li>
		  
		  <li>
			<a href="/categories" title="All the categories.">
			  <i class="fa fa-folder"></i>Categories
			</a>
		  </li>
		  
		  <li>
			<a href="/tags" title="All the tags.">
			  <i class="fa fa-tags"></i>Tags
			</a>
		  </li>
		  
		  <li>
			<a href="/about" title="About me.">
			  <i class="fa fa-user"></i>About
			</a>
		  </li>
		  
		</ul>
      </div>
    </div> <!-- container -->
</nav>
<div class="clearfix"></div>

  <div class="container">
  	<div class="content">
    	 
	
		<div class="page-header">		
			<h1> Graphical-Models-Notes</h1>
		</div>		
	



<div class="row page">
	<!-- cols -->
	
	<div class="col-md-12">
	

			

	<!-- content -->
	<div class="mypage">		
	    <h2 id="Grapical_Model">Grapical Model</h2><h3 id="Probalistic_Graphical_Model_Representation">Probalistic Graphical Model Representation</h3><p><strong>NO FREE LUNCH theory</strong>: You must make assumptions before you learn anything!! If you do not make assumptions, you only can make predictions that appears in training data.</p>
<p><strong>Learning:</strong> Searching in hypothsis space == optimization a function.<br><strong>Machine learning good example</strong> 曲线拟合，我们的assumption是曲线时smooth的，如果给一堆数据：</p>
<table>
<thead>
<tr>
<th>Data</th>
<th>Lable</th>
</tr>
</thead>
<tbody>
<tr>
<td>000</td>
<td>1</td>
</tr>
<tr>
<td>001</td>
<td>0</td>
</tr>
<tr>
<td>010</td>
<td>0</td>
</tr>
<tr>
<td>011</td>
<td>0</td>
</tr>
<tr>
<td>100</td>
<td>1</td>
</tr>
<tr>
<td>111</td>
<td>?</td>
</tr>
</tbody>
</table>
<p>预测111的lable，这里如果我们不做什么假设的话是不可以得到lable的。</p>
<p><strong>Markov Random Field:</strong><br>$$P\left(X\right) = \frac{1}{Z}\prod_{cliques~c} \psi_c\left(x_c \right)$$</p>
<p>$$Z = \sum_x \prod_{cliques~c} \psi_c\left(x_c \right)$$</p>
<p>计算Z要花费指数的时间<br>一般情况下我们用$\log$来表示$\psi \left(x \right)$<br>$$\psi_c \left(x_c \right) = exp \left(-H_c\left(x_c \right) \right)$$<br>这里$H_c\left(x_c \right)$是能量函数。</p>
<p>于是$P\left(x\right) = \frac{1}{Z} exp \left(-\sum_{cliques~c} H_c\left(x_c\right) \right) = \frac{1}{Z}exp\left(-H\left(X\right)\right)$</p>
<p>$H\left(X \right)$ is called “free energy” function</p>
<p><strong>Ising Models</strong></p>
<p>Nodes are arranged in a regular topology (often a regular packing grid) and connected only to their geometric neighbours.<br>Energy function:<br>$$H\left(x\right) = \sum_{ij} \beta_{ij} x_i x_j + \sum_i \alpha_i x_i$$</p>
<p><strong>Relations beteen directed graph &amp; undirected graph</strong><br>两者不能相互转化。</p>
<p><strong>Exponential Family</strong><br>很多分布都可以看成指数家族的一个特例（Uniform distribution是一个例外），定义如下：<br>$$p\left(x|\eta\right) = h\left(x\right)exp \left(\eta^{T}T\left(x\right) - A\left(\eta \right)\right)$$<br>$$p\left(x|\eta\right) = \frac{1}{Z\left(\eta \right)}h\left(x\right)exp\left(\eta^{T} T\left(x\right) \right)$$</p>
<ul>
<li>Natural parameter $\eta$</li>
<li>Function $T\left(x\right)$ is the sufficient statistic(Given training data, 如果知道了其sufficient statistic，这样我们就可以把原来的training数据扔掉了)</li>
<li>Function $A\left(x\right) = \log Z\left(\eta \right)$is the log normalizer</li>
<li>Examples: Bernoulli, binomial/geometric/negative-binomial, Poisson, gamma, multinomial, Gaussian, …</li>
</ul>
<p><strong>Moments</strong><br>We can easily compute moments of any exponential family distribution by taking the derivatives of the log normalizer $A\left(\eta \right)$.<br>The $q^{th}$ derivative gives the $q^{th}$ centred moment.<br>$$\frac{dA\left(\eta \right)}{d \eta} = mean$$<br>$$\frac{d^{2}A\left(\eta \right)}{d^{2} \eta} = variance$$<br>当sufficient statistic是vector时，需要求偏导，而不是导数了。</p>
<p><strong>GLM</strong><br>Generalized Linear Models: p(y|x) is exponential family with conditional mean $ \mu_i= f_\i(\theta^{T}x)$.</p>
<h3 id="Parameter_Learning_in_Graphical_Models">Parameter Learning in Graphical Models</h3><p><strong>NO Latent variable</strong><br>Given training data, 我们对其进行建模，<strong>SUPPOESE</strong>这组数据服从某种模型（Gaussian,Multinomial…）<br>比如线性回归，我们可以认为$p\left(y|x\right) = gaussian\left(y|\theta^{T}x,\sigma^{2} \right)$<br>利用maxmum log likehood对参数进行求解。得到的参数$\theta$与loss function得到的一致。<br><strong>关于sufficient statistics的几点说明</strong></p>
<ul>
<li>In the examples above, the sufficient statistics were merely sums (counts) of the data:</li>
</ul>
<table>
<thead>
<tr>
<th>Distribution</th>
<th>Sufficient Statistics</th>
</tr>
</thead>
<tbody>
<tr>
<td>Bernoulli:</td>
<td>number of heads, tails</td>
</tr>
<tr>
<td>Multinomial:</td>
<td>number of each type</td>
</tr>
<tr>
<td>Gaussian:</td>
<td>mean, mean-square</td>
</tr>
<tr>
<td>Regression:</td>
<td>correlations</td>
</tr>
</tbody>
</table>
<ul>
<li>this is true for all exponential family models: sufficient statistics are the average natural parameters.</li>
<li>只要指数家族模型才有简单的sufficient statistics<br><strong>Generative v.s Descriminative model</strong></li>
<li>Generative Model: 直接对$p\left(x,y\right)$进行建模，在预测时用bayes rule来推断条件概率$p\left(y|x\right)$。通过G-M可以做密度估计(density estimation)</li>
<li>Discriminative Model:直接对$p\left(y|x\right)$进行建模。目标驱动化，如做regression。</li>
</ul>
<p><strong>Generative model for classification</strong></p>
<ul>
<li>$p\left(x,y\right) = p\left(y\right)p\left(x|y\right)$这里$p\left(y\right)$时某类的prior information。$p\left(x|y\right)$是某一类的条件特征分布。</li>
<li>prior: Bernoulli or Multimomial。</li>
<li>class-conditional distribution:如果数据是continuous，一般使用Gaussian class-conditional.$p\left(x|y=k,\theta\right) = \frac{1}{|2\pi \sum^{\frac{1}{2}}|}exp(-\frac{1}{2} \left(\left(x-\mu_k\right) \sum^{-1} \left(x-\mu_k \right)\right))$（Gaussion discriminative model，在Andrew Ng的stanford课上有详细推导）</li>
<li>Using MLE，The maximum likelihood fit of a Gaussian to some data is the Gaussian whose mean is equal to the data mean and whose covariance is equal to the sample covariance.</li>
<li>如果data比较少，或者＃ of data &lt;&lt; dim of feature ，有一些以下Regularizations：</li>
</ul>
<ol>
<li>Assuming all covariance are the same!==&gt; fish discriminant analysis</li>
<li>Assuming the covariance matrix is diagnal…(boundary是linear的)</li>
<li>add a bit of the identity matrix to each sample covariance. This “fattens it up” in directions where there wasn’t enough data. Equivalent to using a “Wishart prior” on the covariance matrix.(这一块不是很理解)</li>
</ol>
<ul>
<li>既然已经有了$p\left(x|y,\theta\right)$，我们的目标是$p\left(y|x,\theta\right)$，通过bayes rule：<br>$$p\left(y=k|x,\theta\right) = \frac{e^{\beta_k^{T}x}}{\sum_je^{\beta_j^{T}x}}$$<br>此时$\beta_k = \mu_k^{T}\sum^{-1}x-\mu_k^{T}\sum_{-1}\mu_k /2+\log \pi_k$</li>
</ul>
<p><strong>Structure learning in bayesian network of tree structure</strong><br>原则上我们要search所有的组合，然后选择likelihood最大的那一个。但是，这个问题可以转换到一个传统的数据结构的问题，我们可以使用最大生成树！<br>既然可以使用最大生成树，我们就要来推导一下这里的edge的weight。likelihood function为:<br>$$l\left(\theta;D \right) = \sum_{x \in V_all}N\left(x\right)\log p\left(x\right) = \sum_x N\left(x\right)\left(\log \left(x_r\right)+\sum_{i\neq r}\log p\left(x_i|\pi_i\right)\right)$$</p>
<h3 id="Latent_Variable_Learning_in_Graphical_Models(Using_EM_algorithm)">Latent Variable Learning in Graphical Models(Using EM algorithm)</h3><h3 id="Inference_in_Graphical_Model">Inference in Graphical Model</h3>	  
	</div>

	<div>
  	<center>
	<div class="pagination">
<ul class="pagination">
	 
</ul>
</div>

    </center>
	</div>
	
	<!-- comment -->
	
<section id="comment">

    <h1 class="title">留言</h1>

    <!-- 多说评论框 start -->
    <div class="ds-thread" data-thread-key="drafts/Graphical-Models-Notes.html" data-title="Graphical-Models-Notes" data-url="http://yoursite.com/drafts/Graphical-Models-Notes.html"></div>
    <!-- 多说评论框 end -->

    <!-- 多说公共JS代码 start (一个网页只需插入一次) -->
    <script type="text/javascript">
    var duoshuoQuery = {short_name:"替换成你获取的通用代码中的short_name"};
        (function() {
            var ds = document.createElement('script');
            ds.type = 'text/javascript';ds.async = true;
            ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
            ds.charset = 'UTF-8';
            (document.getElementsByTagName('head')[0] 
             || document.getElementsByTagName('body')[0]).appendChild(ds);
        })();
        </script>
    <!-- 多说公共JS代码 end -->
</section>

	
	</div> <!-- col-md-9/col-md-12 -->
	
	

</div><!-- row -->

	</div>
  </div>
  <div class="container-narrow">
  <footer> <p>
  &copy; 2015 Yong Jiang
  
      with help from <a href="http://hexo.io/" target="_blank">Hexo</a> and <a href="http://getbootstrap.com/" target="_blank">Twitter Bootstrap</a>. Theme by <a href="http://github.com/wzpan/hexo-theme-freemind/">Freemind</a>.    
</p> </footer>
</div> <!-- container-narrow -->
  
<a id="gotop" href="#">   
  <span>▲</span> 
</a>

<script src="/js/jquery.imagesloaded.min.js"></script>
<script src="/js/gallery.js"></script>
<script src="/js/bootstrap.min.js"></script>
<script src="/js/main.js"></script>


<script type="text/javascript">
  var duoshuoQuery = { short_name: 'jiangyong' };
  (function() {
    var ds = document.createElement('script');
    ds.type = 'text/javascript';
    ds.async = true;
    ds.src = 'http://static.duoshuo.com/embed.js';
    ds.charset = 'UTF-8';
    (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(ds);
  })();
</script>


<link rel="stylesheet" href="/fancybox/jquery.fancybox.css" media="screen" type="text/css">
<script src="/fancybox/jquery.fancybox.pack.js"></script>
<script type="text/javascript">
(function($){
  $('.fancybox').fancybox();
})(jQuery);
</script>

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
</body>
   </html>
