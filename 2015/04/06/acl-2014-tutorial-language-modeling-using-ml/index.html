<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>acl-2014-tutorial-language_modeling_using_ml | SunShining</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="要做AI的project，读了一些paper和tutorial，这里做一些记录。这篇是来自牛津大学NLP组关于language modeling的tutorial。名字叫New Directions in Vector Space Models of Meaning。tutorial两个目的：

Learning vector representations for words
Learning">
<meta property="og:type" content="article">
<meta property="og:title" content="acl-2014-tutorial-language_modeling_using_ml">
<meta property="og:url" content="http://yoursite.com/2015/04/06/acl-2014-tutorial-language-modeling-using-ml/index.html">
<meta property="og:site_name" content="SunShining">
<meta property="og:description" content="要做AI的project，读了一些paper和tutorial，这里做一些记录。这篇是来自牛津大学NLP组关于language modeling的tutorial。名字叫New Directions in Vector Space Models of Meaning。tutorial两个目的：

Learning vector representations for words
Learning">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="acl-2014-tutorial-language_modeling_using_ml">
<meta name="twitter:description" content="要做AI的project，读了一些paper和tutorial，这里做一些记录。这篇是来自牛津大学NLP组关于language modeling的tutorial。名字叫New Directions in Vector Space Models of Meaning。tutorial两个目的：

Learning vector representations for words
Learning">
  
    <link rel="alternative" href="/atom.xml" title="SunShining" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  
</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SunShining</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-home-icon" class="nav-icon" href="/"></a>
        
          <a id="nav-archives-icon" class="nav-icon" href="/archives"></a>
        
          <a id="nav-about-icon" class="nav-icon" href="/about"></a>
        
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-acl-2014-tutorial-language-modeling-using-ml" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      acl-2014-tutorial-language_modeling_using_ml
    </h1>
  

      </header>
    
    <time class="article-date" datetime="2015-04-06T14:28:12.000Z" itemprop="datePublished">04-06-2015</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>要做AI的project，读了一些paper和tutorial，这里做一些记录。这篇是来自牛津大学NLP组关于language modeling的tutorial。名字叫<strong>New Directions in Vector Space Models of Meaning</strong>。tutorial两个目的：</p>
<ul>
<li>Learning vector representations for words</li>
<li>Learning how to compose them to get vector representations for phrases/sentences/documents<h3 id="Menu四部分:">Menu四部分:</h3></li>
</ul>
<ol>
<li>Distributional Semantics</li>
<li>Neural Distributed Representations</li>
<li>Semantic Composition</li>
<li>Last Words</li>
</ol>
<p>在这里我们对每个词用一个vector来表示。这样词与词之间的similarity关系就可以用一些距离度量函数来度量。比如<strong>Cosine Similarity</strong>:<br>$$\cos \left( x,y \right) = \frac{xy}{||x|| \times ||y||}$$<br>或者其他的相似度衡量方法:</p>
<ul>
<li>Euclidean Distance</li>
<li>Lin</li>
<li>Jaccard</li>
<li>Dice</li>
<li>KL divergence<br>有需要的时候再wiki一下吧。。<br>用Vector Representation看起来比较Intuitive motivated。这里分析一下好坏：</li>
<li>Pros: Easy to obtain, vectors are interpretable</li>
<li>Cons: Involves a large number of design choices (what weighting scheme? what similarity measure?)</li>
<li>Problems: Going from word to sentence representations is non-trivial, and no clear intuitions exist.<br>于是问题来了，我们怎么样避免这么多种选择来解决问题？Bengio在2003年提出了用神经网络的方法来对language进行表示。<blockquote>
<p>Twenty years ago log-linear models freed us from the shackles of simple multinomial parametrisations, but imposed the tyranny of feature engineering.</p>
</blockquote>
</li>
</ul>
<p>从基本的Log-linear model for classification开始考虑：<br>这里Feature: $\phi \left( x \right) \in R^{D}$，每一个weight$\lambda _k \in R^{D}$（$k \in {1,…K}$）。因此，我们可以如下建立模型：Given 一个instance $x$，判断其归属于哪一类的概率为：<br>$$p\left( C_k|x \right) = \frac{exp\left( \lambda _k^{T} \phi\left(x\right) \right)}{\sum_j^{k}exp\left( \lambda _j^{T} \phi \left( x\right) \right)}$$<br>Log-linear model的参数是$\lambda$，在training中我们需要计算Gradient：<br>$$\frac{\partial}{\partial \lambda_j}[-\log p\left(C_k|x \right)] = p\left(C_j|x \right)\phi \left(x \right) - \delta \left(j,k\right)\phi\left(x\right)$$<br>$\delta \left(j,k \right)$ is the Kronecker delta function which is 1 if $j = k$ and 0 otherwise。<br>有了log-linear model，我们用来提出log-linear language model：<br>Classify the next word $w_n$ given $w_n-1$, $w_n-2$</p>
<p>TBA…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/04/06/acl-2014-tutorial-language-modeling-using-ml/" data-id="ci8oifzyb00023ktsgi6rtf5b" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-learning/">Machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/language-modeling/">language modeling</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/natural-language-proccessing/">natural language proccessing</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/04/07/Graphical-Models-Notes/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          Graphical-Models-Notes
        
      </div>
    </a>
  
  
    <a href="/2015/04/05/PRML-reading-notes/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">PRML reading notes</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Yong Jiang<br>
      <a href="https://github.com/steven5538/hexo-theme-athena" target="_blank">Athena</a> by <a href="http://steven5538.tw" target="_blank">Steven5538</a> | Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </div>
</body>
</html>