<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <title>PRML reading notes | SunShining</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="PRML(Pattern Recognition and Machine Learning)这本书正式开始阅读是从去年九月份。从一开始看的晕晕乎乎，到现在能够看进去，这中间也走了不少弯路。现在重新读一遍，跟随着Toronto大学的统计机器学习课程，以此blog记录一下阅读笔记。
ch1 Introduction机器学习主要分为有监督的学习和无监督学习，它们之间的区别在于target是否给定。在有监">
<meta property="og:type" content="article">
<meta property="og:title" content="PRML reading notes">
<meta property="og:url" content="http://yoursite.com/2015/04/05/PRML-reading-notes/index.html">
<meta property="og:site_name" content="SunShining">
<meta property="og:description" content="PRML(Pattern Recognition and Machine Learning)这本书正式开始阅读是从去年九月份。从一开始看的晕晕乎乎，到现在能够看进去，这中间也走了不少弯路。现在重新读一遍，跟随着Toronto大学的统计机器学习课程，以此blog记录一下阅读笔记。
ch1 Introduction机器学习主要分为有监督的学习和无监督学习，它们之间的区别在于target是否给定。在有监">
<meta property="og:image" content="http://ww1.sinaimg.cn/mw690/6dfbc26fjw1eqv29oa539j20nb0ebgqv.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/mw690/6dfbc26fjw1eqv2dl7cxej20y30frq72.jpg">
<meta property="og:image" content="http://ww2.sinaimg.cn/mw690/6dfbc26fjw1eqvt3fb3v2j20ak07v74e.jpg">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="PRML reading notes">
<meta name="twitter:description" content="PRML(Pattern Recognition and Machine Learning)这本书正式开始阅读是从去年九月份。从一开始看的晕晕乎乎，到现在能够看进去，这中间也走了不少弯路。现在重新读一遍，跟随着Toronto大学的统计机器学习课程，以此blog记录一下阅读笔记。
ch1 Introduction机器学习主要分为有监督的学习和无监督学习，它们之间的区别在于target是否给定。在有监">
  
    <link rel="alternative" href="/atom.xml" title="SunShining" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link href="//fonts.googleapis.com/css?family=Ubuntu" rel="stylesheet" type="text/css">
  <link rel="stylesheet" href="/css/style.css" type="text/css">
  
</head>
<body>
  <div id="container">
    <div id="wrap">
      <header id="header">
  <div id="header-outer" class="outer">
    <div id="header-title" class="inner">
      <h1 id="logo-wrap">
        <a href="/" id="logo">SunShining</a>
      </h1>
      
    </div>
    <div id="header-inner" class="inner">
      <nav id="sub-nav">
        
          <a id="nav-home-icon" class="nav-icon" href="/"></a>
        
          <a id="nav-archives-icon" class="nav-icon" href="/archives"></a>
        
          <a id="nav-about-icon" class="nav-icon" href="/about"></a>
        
        
          <a id="nav-rss-link" class="nav-icon" href="/atom.xml" title="RSS Feed"></a>
        
      </nav>
    </div>
  </div>
</header>
      <div class="outer">
        <section id="main"><article id="post-PRML-reading-notes" class="article article-type-post" itemscope itemprop="blogPost">
  <div class="article-meta">
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      PRML reading notes
    </h1>
  

      </header>
    
    <time class="article-date" datetime="2015-04-05T13:50:52.000Z" itemprop="datePublished">04-05-2015</time>
    
  </div>
  <div class="article-inner">
    <div class="article-entry" itemprop="articleBody">
      
        <p>PRML(Pattern Recognition and Machine Learning)这本书正式开始阅读是从去年九月份。从一开始看的晕晕乎乎，到现在能够看进去，这中间也走了不少弯路。现在重新读一遍，跟随着Toronto大学的<a href="http://www.cs.toronto.edu/~rsalakhu/STA4273_2015/" target="_blank" rel="external">统计机器学习</a>课程，以此blog记录一下阅读笔记。</p>
<h2 id="ch1_Introduction">ch1 Introduction</h2><p><img src="http://ww1.sinaimg.cn/mw690/6dfbc26fjw1eqv29oa539j20nb0ebgqv.jpg" alt="Machine learning: a big picture"><br>机器学习主要分为有监督的学习和无监督学习，它们之间的区别在于target是否给定。在有监督学习中，target给定，若是离散值，比如给一张动物的图片，判断它是小狗还是小猫，这类问题是分类问题（Classification）；若取连续值，比如预测上海某个小区的房价，则是回归问题（Regression）。而在无监督学习中，target不存在，这里有density estimation, clustering, dimensionality reduction, finding hidden explanation等等任务。<br><img src="http://ww2.sinaimg.cn/mw690/6dfbc26fjw1eqv2dl7cxej20y30frq72.jpg" alt="Classification: an example"></p>
<h3 id="ch_1-1_Exmaple:_Polynomial_Curve_Fitting">ch 1.1 Exmaple: Polynomial Curve Fitting</h3><p>我们从最简单的回归问题（曲线拟合）开始说起，Given 一系列训练数据$\left( x^{\left( 1\right) },x^{\left( 2\right) },…,x^{\left( N\right) }\right) ^{T}$, 每一个$x^{i}=x^{i}_1…x^{i}_d$。它们对应的target值$y=(y_1,…,y_N)^{T}$。我们认为$x$与$y$的关系是线性关系，因此，我们对每一个$x^{\left( i \right)}$的预测值<br>$${y(x^{\left( i \right)},w) = \left( x^{\left( i \right)} \right)^{T}w}$$<br>这里我们可以写成<br>$${y(X,w) = X^{T}w}$$<br>注意$X$是一个$N \times \left( d+1 \right)$的矩阵。<br>我们希望通过最小化一个loss function来获得最好的$w$，在这里定义loss function$E\left( w \right)$为squred error，<br>$$E\left( w \right) = \frac{1}{2} (Xw - y)^{T}(Xw - y)$$<br>如果$X^{T}X$是非奇异的矩阵，我们可以求出最优解<br>$$w^{*} = \left( X^{T}X \right)^{-1}X^{T}y$$<br>但是在实际中如果N很大，这里矩阵运算将非常耗时。在matlab下面做了个实验，当N=10000时，只是做$X^{T}X$就要耗时13秒。显然这种方法在大规模实际应用中不可取。<br>另外，这里的linear models是指关于coeffients $w$的线性函数，而不是关于$x$的线性函数。<br>好的，既然已经有了线性模型的解决方法，我们用它来对一个$\sin \left( 2\pi x\right)$进行拟合。我们从这个函数中sampling出来一些data，如下图<br><img src="http://ww2.sinaimg.cn/mw690/6dfbc26fjw1eqvt3fb3v2j20ak07v74e.jpg" alt="$\sin \left( 2\pi x\right)$"><br>我们用一个多项式的函数来拟合这些数据，</p>
<p>TBA…</p>

      
    </div>
    <footer class="article-footer">
      <a data-url="http://yoursite.com/2015/04/05/PRML-reading-notes/" data-id="ci86lb81u000d28tsr2342psq" class="article-share-link">Share</a>
      
      
  <ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/Machine-learning/">Machine learning</a></li><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/PRML/">PRML</a></li></ul>

    </footer>
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2015/04/06/acl-2014-tutorial-language-modeling-using-ml/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Newer</strong>
      <div class="article-nav-title">
        
          acl-2014-tutorial-language_modeling_using_ml
        
      </div>
    </a>
  
  
    <a href="/2015/04/05/hello-world/" id="article-nav-older" class="article-nav-link-wrap">
      <strong class="article-nav-caption">Older</strong>
      <div class="article-nav-title">Hello World</div>
    </a>
  
</nav>

  
</article>

</section>
        
      </div>
      <footer id="footer">
  
  <div class="outer">
    <div id="footer-info" class="inner">
      &copy; 2015 Yong Jiang<br>
      <a href="https://github.com/steven5538/hexo-theme-athena" target="_blank">Athena</a> by <a href="http://steven5538.tw" target="_blank">Steven5538</a> | Powered by <a href="http://hexo.io/" target="_blank">Hexo</a>
    </div>
  </div>
</footer>
    </div>
    

<script src="//ajax.googleapis.com/ajax/libs/jquery/2.0.3/jquery.min.js"></script>


  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">
  <script src="/fancybox/jquery.fancybox.pack.js" type="text/javascript"></script>


<script src="/js/script.js" type="text/javascript"></script>

<script type="text/x-mathjax-config"> 
MathJax.Hub.Config({ 
  tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} 
}); 
</script>
<script type="text/javascript"
   src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>
  </div>
</body>
</html>